{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/79 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:00<00:00, 395.73it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 476.12it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 498.84it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 504.34it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 479.81it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 428.74it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 442.41it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 479.27it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 511.85it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 399.03it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 288.71it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 516.99it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 533.38it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 501.83it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 543.09it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 466.62it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 443.96it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 462.58it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 464.91it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 407.34it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 453.70it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 523.88it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 507.61it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 483.03it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 499.77it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 404.09it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 441.18it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 461.35it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 520.21it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 519.88it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 499.86it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 472.37it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 420.47it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 348.21it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 411.26it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 512.34it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 455.48it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 474.30it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 493.57it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 521.57it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 475.46it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 482.36it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 428.48it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 480.30it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 500.07it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 423.19it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 496.94it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 497.01it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 483.32it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 461.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 50/400, Loss: 0.4462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:00<00:00, 461.24it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 440.31it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 446.97it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 461.54it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 413.36it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 483.83it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 463.08it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 352.97it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 458.03it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 420.43it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 505.46it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 492.87it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 487.93it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 445.97it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 392.94it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 445.47it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 529.57it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 513.06it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 415.48it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 450.08it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 457.95it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 375.41it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 511.09it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 488.43it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 460.29it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 445.08it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 458.67it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 479.17it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 374.04it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 359.42it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 382.66it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 424.03it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 463.87it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 425.64it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 447.72it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 385.17it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 375.61it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 448.05it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 395.00it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 458.53it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 287.60it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 446.96it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 360.25it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 436.57it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 423.93it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 419.47it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 405.03it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 406.79it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 415.38it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 420.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 100/400, Loss: 0.4499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:00<00:00, 439.97it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 329.58it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 443.46it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 442.95it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 411.57it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 379.69it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 413.58it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 469.58it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 460.68it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 430.52it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 354.98it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 459.01it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 507.61it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 456.55it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 529.21it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 351.23it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 416.92it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 385.22it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 396.23it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 540.12it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 415.05it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 402.33it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 513.39it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 456.52it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 467.71it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 357.34it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 437.33it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 450.33it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 465.85it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 486.93it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 441.70it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 449.33it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 439.54it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 485.38it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 489.90it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 477.71it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 484.97it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 506.36it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 475.04it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 483.88it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 446.42it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 453.76it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 518.56it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 499.49it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 472.45it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 414.14it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 474.90it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 464.70it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 472.47it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 488.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 150/400, Loss: 0.4447\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:00<00:00, 335.99it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 487.94it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 520.50it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 487.59it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 493.39it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 495.93it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 455.31it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 362.83it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 322.01it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 497.65it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 481.90it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 455.17it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 458.09it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 452.37it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 518.05it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 496.54it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 430.99it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 459.04it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 438.51it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 464.03it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 417.25it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 479.27it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 492.18it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 444.38it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 487.66it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 355.05it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 511.95it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 534.20it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 456.07it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 564.25it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 524.60it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 527.62it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 557.71it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 513.72it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 517.87it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 525.17it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 518.07it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 546.99it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 496.76it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 398.01it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 453.61it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 298.39it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 447.42it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 503.01it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 431.27it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 454.36it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 424.51it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 413.59it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 443.12it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 472.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 200/400, Loss: 0.4516\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:00<00:00, 349.31it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 469.38it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 513.96it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 504.13it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 543.61it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 442.39it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 512.47it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 498.12it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 534.61it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 512.31it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 425.93it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 487.08it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 518.91it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 518.21it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 523.44it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 510.15it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 484.62it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 527.00it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 523.12it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 533.32it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 489.00it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 475.64it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 419.73it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 454.71it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 469.17it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 479.68it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 496.31it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 515.74it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 400.93it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 441.14it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 480.64it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 423.73it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 323.93it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 474.67it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 444.13it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 537.55it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 542.57it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 517.53it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 502.53it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 520.84it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 498.56it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 482.33it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 456.51it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 429.43it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 475.02it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 435.21it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 410.36it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 510.67it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 469.07it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 410.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 250/400, Loss: 0.4442\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:00<00:00, 414.79it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 458.65it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 324.48it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 487.97it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 429.72it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 517.47it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 493.80it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 525.98it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 541.39it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 529.04it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 565.37it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 503.11it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 506.30it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 466.69it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 423.82it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 506.78it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 471.69it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 510.52it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 534.20it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 502.83it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 452.19it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 489.55it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 503.70it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 463.13it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 518.56it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 502.04it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 500.66it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 512.35it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 410.94it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 526.41it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 501.53it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 518.31it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 444.38it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 512.83it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 486.48it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 480.97it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 427.81it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 445.76it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 415.53it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 408.24it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 461.58it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 368.28it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 396.29it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 439.16it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 501.24it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 330.95it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 451.75it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 474.86it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 423.66it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 502.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 300/400, Loss: 0.4317\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:00<00:00, 505.41it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 382.46it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 422.41it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 462.98it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 479.59it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 549.28it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 501.82it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 546.36it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 480.23it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 491.76it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 504.23it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 502.75it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 466.11it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 339.58it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 451.81it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 452.39it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 460.16it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 482.20it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 374.41it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 400.53it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 459.04it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 448.58it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 458.01it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 405.75it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 518.28it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 487.75it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 519.79it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 531.05it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 506.97it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 505.75it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 501.75it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 543.44it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 520.09it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 334.65it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 464.41it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 434.32it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 454.93it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 521.67it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 507.57it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 511.65it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 515.44it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 518.04it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 505.72it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 487.94it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 512.80it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 473.26it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 485.63it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 494.45it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 441.22it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 332.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 350/400, Loss: 0.4437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 79/79 [00:00<00:00, 419.04it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 488.18it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 526.61it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 496.55it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 503.76it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 517.55it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 462.90it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 438.55it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 409.41it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 481.34it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 347.50it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 411.10it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 475.49it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 375.84it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 432.23it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 492.27it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 493.73it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 476.97it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 489.59it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 565.63it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 530.71it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 472.51it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 486.82it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 542.59it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 520.90it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 508.65it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 454.51it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 481.48it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 500.15it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 415.81it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 433.61it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 438.48it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 525.64it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 323.86it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 421.48it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 397.13it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 364.14it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 420.30it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 482.81it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 430.76it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 419.13it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 489.28it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 484.87it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 449.09it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 446.06it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 471.26it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 424.71it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 480.83it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 523.29it/s]\n",
      "100%|██████████| 79/79 [00:00<00:00, 497.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 400/400, Loss: 0.4406\n",
      "Diffusion process animation saved as 'diffusion_process.gif'\n",
      "Training loss plot saved as 'training_loss.png'\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.datasets import make_blobs\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import imageio\n",
    "\n",
    "# Hyperparameters\n",
    "timesteps = 200\n",
    "batch_size = 512\n",
    "epochs = 200\n",
    "learning_rate = 1e-3\n",
    "\n",
    "# Generate two Gaussians dataset in corners (4,4) and (4,-4)\n",
    "X, _ = make_blobs(n_samples=10000, centers=[(4,4), (4,-4)], cluster_std=0.5, random_state=42)\n",
    "X = torch.tensor(X, dtype=torch.float32)\n",
    "\n",
    "# Define beta schedule\n",
    "def linear_beta_schedule(timesteps):\n",
    "    beta_start = 0.0001\n",
    "    beta_end = 0.02\n",
    "    return torch.linspace(beta_start, beta_end, timesteps)\n",
    "\n",
    "betas = linear_beta_schedule(timesteps)\n",
    "alphas = 1. - betas\n",
    "alphas_cumprod = torch.cumprod(alphas, axis=0)\n",
    "sqrt_alphas_cumprod = torch.sqrt(alphas_cumprod)\n",
    "sqrt_one_minus_alphas_cumprod = torch.sqrt(1. - alphas_cumprod)\n",
    "\n",
    "# Helper function to extract the appropriate t index for a batch of indices\n",
    "def extract(a, t, x_shape):\n",
    "    batch_size = t.shape[0]\n",
    "    out = a.gather(-1, t)\n",
    "    return out.reshape(batch_size, *((1,) * (len(x_shape) - 1)))\n",
    "\n",
    "# Forward diffusion process\n",
    "def q_sample(x_start, t, noise=None):\n",
    "    if noise is None:\n",
    "        noise = torch.randn_like(x_start)\n",
    "\n",
    "    sqrt_alphas_cumprod_t = extract(sqrt_alphas_cumprod, t, x_start.shape)\n",
    "    sqrt_one_minus_alphas_cumprod_t = extract(sqrt_one_minus_alphas_cumprod, t, x_start.shape)\n",
    "\n",
    "    return sqrt_alphas_cumprod_t * x_start + sqrt_one_minus_alphas_cumprod_t * noise\n",
    "\n",
    "# Simple MLP model\n",
    "class SimpleMLP(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(2 + 1, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x, t):\n",
    "        x = torch.cat([x, t.unsqueeze(-1)], dim=-1)\n",
    "        return self.net(x)\n",
    "\n",
    "# Training function\n",
    "def train(model, dataloader, optimizer, device):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    for x in tqdm(dataloader):\n",
    "        x = x[0].to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        t = torch.randint(0, timesteps, (x.shape[0],), device=device).long()\n",
    "        noise = torch.randn_like(x)\n",
    "        x_noisy = q_sample(x, t, noise)\n",
    "        noise_pred = model(x_noisy, t.float())\n",
    "        loss = nn.MSELoss()(noise_pred, noise)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item()\n",
    "    \n",
    "    return total_loss / len(dataloader)\n",
    "\n",
    "# Initialize model, optimizer, and dataloader\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = SimpleMLP().to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "dataloader = DataLoader(TensorDataset(X), batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Training loop\n",
    "losses = []\n",
    "for epoch in range(epochs):\n",
    "    loss = train(model, dataloader, optimizer, device)\n",
    "    losses.append(loss)\n",
    "    if (epoch + 1) % 50 == 0:\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {loss:.4f}\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Sampling function\n",
    "@torch.no_grad()\n",
    "def sample(model, n_samples, device, source_samples, target_samples):\n",
    "    model.eval()\n",
    "    x = torch.randn(n_samples, 2).to(device)\n",
    "    frames = []\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    scatter = ax.scatter([], [], s=25, c='red', alpha=0.7, label='Generated')\n",
    "    source_scatter = ax.scatter(source_samples[:, 0], source_samples[:, 1], s=30, c='blue', alpha=0.3, label='Source')\n",
    "    target_scatter = ax.scatter(target_samples[:, 0], target_samples[:, 1], s=30, c='green', alpha=0.3, label='Target')\n",
    "    time_text = ax.text(0.05, 0.95, '', transform=ax.transAxes, fontsize=20, horizontalalignment='left', verticalalignment='top')\n",
    "    \n",
    "    # Set axis limits based on the data\n",
    "    all_data = np.vstack((source_samples, target_samples))\n",
    "    x_min, x_max = all_data[:, 0].min(), all_data[:, 0].max()\n",
    "    y_min, y_max = all_data[:, 1].min(), all_data[:, 1].max()\n",
    "    margin = 0.05 * max(x_max - x_min, y_max - y_min)  # Reduced margin\n",
    "    ax.set_xlim(x_min - margin, x_max + margin)\n",
    "    ax.set_ylim(y_min - margin, y_max + margin)\n",
    "    \n",
    "    ax.legend(loc='lower left', fontsize=20)\n",
    "    \n",
    "    # Remove axis and ticks\n",
    "    ax.axis('off')\n",
    "    \n",
    "    def update(frame):\n",
    "        nonlocal x\n",
    "        t = timesteps - 1 - frame\n",
    "        t_batch = torch.full((n_samples,), t, device=device, dtype=torch.long)\n",
    "        predicted_noise = model(x, t_batch.float())\n",
    "        alpha = alphas[t]\n",
    "        alpha_hat = alphas_cumprod[t]\n",
    "        beta = betas[t]\n",
    "        if t > 0:\n",
    "            noise = torch.randn_like(x)\n",
    "        else:\n",
    "            noise = torch.zeros_like(x)\n",
    "        x = 1 / torch.sqrt(alpha) * (x - ((1 - alpha) / (torch.sqrt(1 - alpha_hat))) * predicted_noise) + torch.sqrt(beta) * noise\n",
    "        \n",
    "        scatter.set_offsets(x.cpu().numpy())\n",
    "        time_text.set_text(f't = {frame}/{timesteps}')\n",
    "        return scatter, time_text\n",
    "    \n",
    "    anim = animation.FuncAnimation(fig, update, frames=timesteps, interval=50, blit=True)\n",
    "    \n",
    "    # Save as GIF with tight layout\n",
    "    plt.tight_layout()\n",
    "    anim.save('diffusion_process.gif', writer='pillow', fps=20)\n",
    "    plt.close(fig)\n",
    "    \n",
    "    return x\n",
    "\n",
    "# Generate source and target samples\n",
    "source_samples = torch.randn(2000, 2).numpy()\n",
    "target_samples = X.numpy()[:2000]\n",
    "\n",
    "# Generate samples and create animation\n",
    "samples = sample(model, 3000, device, source_samples, target_samples)\n",
    "\n",
    "# Plot loss with increased font and tick size\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, epochs + 1), losses, linewidth=3)\n",
    "plt.title(\"Training Loss\", fontsize=20)\n",
    "plt.xlabel(\"Epoch\", fontsize=18)\n",
    "plt.ylabel(\"Loss\", fontsize=18)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "\n",
    "# Add red dotted line at minimum value\n",
    "min_loss = min(losses)\n",
    "plt.axhline(y=min_loss, color='red', linestyle=':', linewidth=2)\n",
    "\n",
    "# Add text 'L_diffusion > 0'\n",
    "plt.text(epochs/2, min_loss*1.1, r'$L_\\mathrm{diffusion} > 0$', fontsize=16, \n",
    "         horizontalalignment='center', verticalalignment='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_loss.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "print(\"Diffusion process animation saved as 'diffusion_process.gif'\")\n",
    "print(\"Training loss plot saved as 'training_loss.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Diffusion process animation saved as 'diffusion_process.gif'\n",
      "Training loss plot saved as 'training_loss.png'\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Sampling function\n",
    "@torch.no_grad()\n",
    "def sample(model, n_samples, device, source_samples, target_samples):\n",
    "    model.eval()\n",
    "    x = torch.tensor(source_samples).to(device)  # Start with source samples\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    scatter = ax.scatter([], [], s=25, c='red', alpha=0.7, label='Generated')\n",
    "    source_scatter = ax.scatter(source_samples[:, 0], source_samples[:, 1], s=30, c='blue', alpha=0.3, label='Source')\n",
    "    target_scatter = ax.scatter(target_samples[:, 0], target_samples[:, 1], s=30, c='green', alpha=0.3, label='Target')\n",
    "    time_text = ax.text(0.05, 0.95, '', transform=ax.transAxes, fontsize=20, horizontalalignment='left', verticalalignment='top')\n",
    "    \n",
    "    # Set axis limits based on the data\n",
    "    all_data = np.vstack((source_samples, target_samples))\n",
    "    x_min, x_max = all_data[:, 0].min(), all_data[:, 0].max()\n",
    "    y_min, y_max = all_data[:, 1].min(), all_data[:, 1].max()\n",
    "    margin = 0.05 * max(x_max - x_min, y_max - y_min)  # Reduced margin\n",
    "    ax.set_xlim(x_min - margin, x_max + margin)\n",
    "    ax.set_ylim(y_min - margin, y_max + margin)\n",
    "    \n",
    "    ax.legend(loc='lower left', fontsize=20)\n",
    "    \n",
    "    # Remove axis and ticks\n",
    "    ax.axis('off')\n",
    "    \n",
    "    # Draw lines between initial and final states\n",
    "    lines = [ax.plot([], [], color='red', alpha=0.1, linewidth=0.5)[0] for _ in range(n_samples)]\n",
    "    \n",
    "    def update(frame):\n",
    "        nonlocal x\n",
    "        if frame <= timesteps:\n",
    "            if frame == 0:\n",
    "                # Initial source samples\n",
    "                scatter.set_offsets(x.cpu().numpy())\n",
    "                time_text.set_text('Initial source samples')\n",
    "            else:\n",
    "                t = timesteps - frame\n",
    "                t_batch = torch.full((n_samples,), t, device=device, dtype=torch.long)\n",
    "                predicted_noise = model(x, t_batch.float())\n",
    "                alpha = alphas[t]\n",
    "                alpha_hat = alphas_cumprod[t]\n",
    "                beta = betas[t]\n",
    "                if t > 0:\n",
    "                    noise = torch.randn_like(x)\n",
    "                else:\n",
    "                    noise = torch.zeros_like(x)\n",
    "                x = 1 / torch.sqrt(alpha) * (x - ((1 - alpha) / (torch.sqrt(1 - alpha_hat))) * predicted_noise) + torch.sqrt(beta) * noise\n",
    "                \n",
    "                scatter.set_offsets(x.cpu().numpy())\n",
    "                time_text.set_text(f't = {frame}/{timesteps}')\n",
    "        \n",
    "        # Update lines\n",
    "        for i, line in enumerate(lines):\n",
    "            line.set_data([source_samples[i, 0], x[i, 0].cpu()], [source_samples[i, 1], x[i, 1].cpu()])\n",
    "        \n",
    "        return scatter, time_text, *lines\n",
    "    \n",
    "    anim = animation.FuncAnimation(fig, update, frames=timesteps+20, interval=50, blit=True)\n",
    "    \n",
    "    # Save as GIF with tight layout\n",
    "    plt.tight_layout()\n",
    "    anim.save('diffusion_process.gif', writer='pillow', fps=30)\n",
    "    plt.close(fig)\n",
    "    \n",
    "    return x\n",
    "\n",
    "# Generate source and target samples\n",
    "source_samples = torch.randn(2000, 2).numpy()\n",
    "target_samples = X.numpy()[:2000]\n",
    "\n",
    "# Generate samples and create animation\n",
    "samples = sample(model, 2000, device, source_samples, target_samples)\n",
    "\n",
    "# Plot loss with increased font and tick size\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(range(1, epochs + 1), losses, linewidth=3)\n",
    "plt.title(\"Training Loss\", fontsize=20)\n",
    "plt.xlabel(\"Epoch\", fontsize=18)\n",
    "plt.ylabel(\"Loss\", fontsize=18)\n",
    "plt.xticks(fontsize=14)\n",
    "plt.yticks(fontsize=14)\n",
    "\n",
    "# Add red dotted line at minimum value\n",
    "min_loss = min(losses)\n",
    "plt.axhline(y=min_loss, color='red', linestyle=':', linewidth=2)\n",
    "\n",
    "# Add text 'L_diffusion > 0'\n",
    "plt.text(epochs/2, min_loss*1.1, r'$L_\\mathrm{diffusion} > 0$', fontsize=16, \n",
    "         horizontalalignment='center', verticalalignment='bottom')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('training_loss.png', dpi=300, bbox_inches='tight')\n",
    "plt.close()\n",
    "\n",
    "print(\"Diffusion process animation saved as 'diffusion_process.gif'\")\n",
    "print(\"Training loss plot saved as 'training_loss.png'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2000, 2) <class 'numpy.ndarray'>\n",
      "(2000, 2) <class 'numpy.ndarray'>\n",
      "One step prediction animation saved as 'one_step_prediction.gif'\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Sampling function\n",
    "@torch.no_grad()\n",
    "def sample(model, n_samples, device, source_samples, target_samples):\n",
    "    model.eval()\n",
    "    x = torch.tensor(source_samples).float().to(device)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    scatter = ax.scatter([], [], s=25, c='red', alpha=0.7, label='Generated')\n",
    "    source_scatter = ax.scatter(source_samples[:, 0], source_samples[:, 1], s=30, c='blue', alpha=0.3, label='Source')\n",
    "    target_scatter = ax.scatter(target_samples[:, 0], target_samples[:, 1], s=30, c='green', alpha=0.3, label='Target')\n",
    "    time_text = ax.text(0.05, 0.95, '', transform=ax.transAxes, fontsize=20)\n",
    "    \n",
    "    # Set axis limits based on the data\n",
    "    all_data = np.vstack((source_samples, target_samples))\n",
    "    x_min, x_max = all_data[:, 0].min(), all_data[:, 0].max()\n",
    "    y_min, y_max = all_data[:, 1].min(), all_data[:, 1].max()\n",
    "    margin = 0.1 * max(x_max - x_min, y_max - y_min)\n",
    "    ax.set_xlim(x_min - margin, x_max + margin)\n",
    "    ax.set_ylim(y_min - margin, y_max + margin)\n",
    "    \n",
    "    ax.legend(loc='lower left', fontsize=20)\n",
    "    \n",
    "    # Remove axis and ticks\n",
    "    ax.axis('off')\n",
    "    \n",
    "    # Draw lines between initial and final states\n",
    "    lines = [ax.plot([], [], color='red', alpha=0.1, linewidth=0.5)[0] for _ in range(n_samples)]\n",
    "    \n",
    "    # Number of intermediate frames\n",
    "    n_frames = 30\n",
    "    \n",
    "    # Compute destination samples\n",
    "    t = torch.ones(n_samples, device=device) * (timesteps - 1)  # Start from t=T-1\n",
    "    predicted_noise = model(x, t)\n",
    "    # Use the formula: x_0 = 1/sqrt(alpha_bar_t) * x_t - (1-alpha_bar_t)/sqrt(1-alpha_bar_t) * epsilon_theta\n",
    "    alpha_bar_t = alphas_cumprod[timesteps - 1]\n",
    "    destination_samples = ((1 / torch.sqrt(alpha_bar_t)) * ( x - \n",
    "                               torch.sqrt(1 - alpha_bar_t)  * predicted_noise)).cpu().numpy()\n",
    "    \n",
    "    print(destination_samples.shape, type(destination_samples))\n",
    "    print(source_samples.shape, type(source_samples))\n",
    "\n",
    "    def update(frame):\n",
    "        # Linearly interpolate between source and destination samples\n",
    "        if frame > n_frames:\n",
    "            frame = n_frames\n",
    "        t = frame / (n_frames - 1)\n",
    "        current_samples = (1 - t) * source_samples + t * destination_samples\n",
    "        \n",
    "        scatter.set_offsets(current_samples)\n",
    "        if frame < n_frames:\n",
    "            time_text.set_text(f'Initial source samples')\n",
    "        else:\n",
    "            time_text.set_text(f'One step prediction')\n",
    "        \n",
    "        # Update lines\n",
    "        for i, line in enumerate(lines):\n",
    "            line.set_data([source_samples[i, 0], current_samples[i, 0]], \n",
    "                          [source_samples[i, 1], current_samples[i, 1]])\n",
    "        \n",
    "        return scatter, time_text, *lines\n",
    "    \n",
    "    anim = animation.FuncAnimation(fig, update, frames=n_frames+15, interval=50, blit=True)\n",
    "    \n",
    "    # Save as GIF with tight layout and pause at the end\n",
    "    plt.tight_layout()\n",
    "    anim.save('one_step_prediction.gif', writer='pillow', fps=30)  # Removed save_count argument\n",
    "    plt.close(fig)\n",
    "    \n",
    "    return x\n",
    "\n",
    "# Generate source and target samples\n",
    "source_samples = torch.randn(2000, 2).numpy()\n",
    "target_samples = X.numpy()[:2000]\n",
    "\n",
    "# Generate samples and create animation\n",
    "samples = sample(model, 2000, device, source_samples, target_samples)\n",
    "\n",
    "\n",
    "print(\"One step prediction animation saved as 'one_step_prediction.gif'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-step diffusion animation saved as 'one_step_diffusion.gif'\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.animation as animation\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "# Sampling function\n",
    "@torch.no_grad()\n",
    "def sample(model, n_samples, device, source_samples, target_samples):\n",
    "    model.eval()\n",
    "    x = torch.tensor(source_samples).float().to(device)\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(10, 10))\n",
    "    scatter = ax.scatter([], [], s=25, c='red', alpha=0.7, label='Generated')\n",
    "    source_scatter = ax.scatter(source_samples[:, 0], source_samples[:, 1], s=30, c='blue', alpha=0.3, label='Source')\n",
    "    target_scatter = ax.scatter(target_samples[:, 0], target_samples[:, 1], s=30, c='green', alpha=0.3, label='Target')\n",
    "    time_text = ax.text(0.05, 0.95, '', transform=ax.transAxes, fontsize=20)\n",
    "    \n",
    "    # Set axis limits based on the data\n",
    "    all_data = np.vstack((source_samples, target_samples))\n",
    "    x_min, x_max = all_data[:, 0].min(), all_data[:, 0].max()\n",
    "    y_min, y_max = all_data[:, 1].min(), all_data[:, 1].max()\n",
    "    margin = 0.1 * max(x_max - x_min, y_max - y_min)\n",
    "    ax.set_xlim(x_min - margin, x_max + margin)\n",
    "    ax.set_ylim(y_min - margin, y_max + margin)\n",
    "    \n",
    "    ax.legend(loc='lower left', fontsize=20)\n",
    "    \n",
    "    # Remove axis and ticks\n",
    "    ax.axis('off')\n",
    "    \n",
    "    # Draw lines between initial and final states\n",
    "    lines = [ax.plot([], [], color='red', alpha=0.1, linewidth=0.5)[0] for _ in range(n_samples)]\n",
    "    \n",
    "    def update(frame):\n",
    "        if frame == 0:\n",
    "            current_samples = source_samples\n",
    "        else:\n",
    "            t = torch.ones(n_samples).to(device)  # Changed this line to match dimensions\n",
    "            noise_estimate = model(x, t)\n",
    "            current_samples = (x - noise_estimate).cpu().numpy()\n",
    "        \n",
    "        scatter.set_offsets(current_samples)\n",
    "        time_text.set_text(f't = {frame}')\n",
    "        \n",
    "        # Update lines\n",
    "        for i, line in enumerate(lines):\n",
    "            line.set_data([source_samples[i, 0], current_samples[i, 0]], [source_samples[i, 1], current_samples[i, 1]])\n",
    "        \n",
    "        return scatter, time_text, *lines\n",
    "    \n",
    "    anim = animation.FuncAnimation(fig, update, frames=2, interval=1000, blit=True)\n",
    "    \n",
    "    # Save as GIF with tight layout\n",
    "    plt.tight_layout()\n",
    "    anim.save('one_step_diffusion.gif', writer='pillow', fps=1)\n",
    "    plt.close(fig)\n",
    "    \n",
    "    return x - model(x, torch.ones(n_samples).to(device))  # Changed this line to match dimensions\n",
    "\n",
    "# Generate source and target samples\n",
    "source_samples = torch.randn(2000, 2).numpy()\n",
    "target_samples = X.numpy()[:2000]\n",
    "\n",
    "# Generate samples and create animation\n",
    "samples = sample(model, 2000, device, source_samples, target_samples)\n",
    "\n",
    "print(\"One-step diffusion animation saved as 'one_step_diffusion.gif'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
